<!doctype html>
<html>

<head>
    <meta charset="utf-8">

    <title>Research | SJTU Machine Vision and Intelligence Group</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


    <!-- set page stylesheet -->
    <link rel="stylesheet" href="/css/shared.css" type="text/css">
    <link rel="stylesheet" href="/css/navbar.css" type="text/css">

</head>

<body>

    <div class="container navbar">
        <h2>
            <a class="active" href="/index.html">Home</a>&nbsp;&nbsp;&middot;&nbsp;&nbsp;
            <a href="/research.html">Research</a>&nbsp;&nbsp;&middot;&nbsp;
            <a href="/publications.html">Publications</a>&nbsp;&nbsp;&middot;&nbsp;
            <!-- <a href="/open_source.html">Open Source</a>&nbsp;&nbsp;&middot;&nbsp; -->
            <a href="/awards.html">Awards</a>
        </h2>
    </div>

    <p style="text-align: center;">Cards are reshuffled at each time.</p>

    <div id="content">
        <!-- <p style="text-align: center;">Cards are reshuffled at each time.</p> -->
        <div class="container">
            <h2>
                <li><a href="https://graspnet.net/index.html">General Object Grasping ｜ 通用物体抓取</a>
                </li>
            </h2>
            <!-- width=300 height=200-->
            <br>
            <div class="research_card_line">
                <div class="research">
                    <h3>GraspNet</h3>
                    <!-- insert image here -->
                    <a href="https://arxiv.org/abs/2002.11076">
                        <img src="/img/research/obj_grasping/label_mini.gif" width="280">
                    </a>
                    <p>GraspNet contribute a large-scale grasp pose detection dataset with a unified evaluation
                        system. It contains 97,280 RGB-D image with over one billion grasp poses
                    </p>
                </div>
                <div class="research">
                    <div class="research_name">
                        <h3>AnyGrasp</h3>
                        <a href="https://arxiv.org/abs/2002.11076">
                            <img src="img/research/obj_grasping/anygrasp_1_small.gif" width="280">
                        </a>
                        <p>AnyGrasp is a robot grasping system that is prompt, accurate, flexible, and continuous across
                            spatial and temporal domain using a parallel gripper.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <div class="container">
            <h2>
                <li><a href="http://hake-mvig.cn">Human Activity Understanding ｜ 人类行为理解</a>
            </h2>
            <br>
            <div class="research_card_line">
                <div class="research">
                    <h3><b>
                            <span style="color: red" size="6px">H</span><span style="color: blue"
                                size="6px">A</span><span style="color: red" size="6px">KE</span>
                        </b></h3>
                    <a href="https://arxiv.org/pdf/2202.06851">
                        <img src="img/research/human_activity/HAKE-A2V.gif" width="300">
                    </a>
                    <p>HAKE is a large-scale Human Activity Knowledge Engine (HAKE) based on the human body part
                        states. It has more than 7M+ part state annotations and is still under construction.
                    </p>

                </div>
                <div class="research">
                    <h3>Pangea</h3>
                    <a href="https://arxiv.org/abs/2304.00553">
                        <img src="img/research/human_activity/pangeaTeaser.fb7bf710.jpg" height="160">
                    </a>
                    <br>
                    <p>Pangea is a structured action semantic space given verb taxonomy hierarchy and covering massive
                        actions,
                        bridging "isolated islands" into a "Pangea".
                </div>
            </div>
            <br>
            <br>
            <!-- here -->

        </div>
        <div class="container">
            <h2>
                <li><a href="https://robotflow.ai">Physical-based Robot Simulation ｜ 机器人仿真平台</a>
            </h2>
            <br>
            <!-- here -->
            <div class="research_card_line">
                <div class="research">
                    <h3>RFUniverse</h3>
                    <img src="img/research/simulation/rfuniverse.png" width="280">
                    <p> RFUnivers is simulation environment that integrates three multiphysics coupling
                        effects, namely air-solid interaction, fluid-solid interaction, and heat transfer.
                </div>
                <div class="research">
                    <h3>MultiModal Sensors</h3>
                    <img src="img/research/simulation/tactile.png" width="290">
                    <br><br>
                    <p>MultiModal Sensors system that consist of tactile and IMU for tracking hand's motion and contact
                        dynamics during manipulation tasks.
                </div>
            </div>
            <br>
            <br>
            <!-- here -->
            <br>
            <br>
            <!-- here -->
        </div>

    </div>

    <script>
        window.onload = function () {
            var content = document.getElementById('content');
            var containers = Array.from(content.querySelectorAll('.container'));
            // 随机打乱容器顺序
            containers.sort(function () { return 0.5 - Math.random(); });
            // 清空父容器内容
            content.innerHTML = '';
            // 重新添加打乱顺序后的容器
            containers.forEach(function (div) {
                content.appendChild(div);
            });
        }
    </script>

</body>

</html>