<!doctype html>
<html>

<head>
    <meta charset="utf-8">

    <title>SJTU Machine Vision and Intelligence Group</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


    <!-- set page stylesheet -->
    <link rel="stylesheet" href="/css/shared.css" type="text/css">
    <link rel="stylesheet" href="/css/navbar.css" type="text/css">

</head>

<body>

    <div class="container_bg navbar">
        <h2>
            <a href="/index.html">HOME</a>&nbsp;&nbsp;<span class="delimiter">&middot;</span>&nbsp;&nbsp;
            <a href="/research.html"><strong>RESEARCH</strong></a>&nbsp;&nbsp;<span
                class="delimiter">&middot;</span>&nbsp;
            <a href="/publications.html">PUBLICATTIONS</a>
            <!-- <a href="/open_source.html">Open Source</a>&nbsp;&nbsp;&middot;&nbsp; -->
            <!-- <a href="/awards.html">Awards</a> -->
        </h2>
    </div>

    <div class="container">
        <div id="group" align="center">
            <h1>Machine Vision and Intelligence Group</h1>
        </div>
        <div id="sidebar">
            <img src="/img/avatar.jpg" vspace="30 px" width="250 px" id="me" itemprop="photo"></img>
        </div>

        <div id="bio">

            <br>

            <h1>
                <span itemprop="name">Cewu Lu <font size="6">卢策吾</font> </span>
            </h1>

            <p style="line-height:23px;">
                Professor
                <br>
                <br>
                School of Artificial Intelligence
                <br>
                Shanghai Jiao Tong University
                <br>
                Shanghai, China 200240
                <br>
                <br>
                <br>
                Email: lucewu[at]sjtu[dot]edu[dot]cn

                <br>
            </p>

            <p class="external">
                <a href="https://scholar.google.com/citations?user=QZVQEWAAAAAJ&hl=en" class="first">Google Scholar</a>
            </p>
        </div>
    </div>

    <div class="container">
        <h2>Recruiting</h2>
        <p>
            We are Recruiting Ph.D. students, Master students, Postdocs, and Undergraduate Research Interns. Contact us
            if you are interested in Embodied AI.
        </p>
        <p class="chinese">
            各位同学大家好，我们MVIG实验室诚邀大家加入我们，一起做有影响力与原创的科研！有意向同学请发送邮件至：<a
                href="mailto:lucewu@sjtu.edu.cn">lucewu@sjtu.edu.cn</a> 和 <a
                href="mailto:tami@sjtu.edu.cn">tami@sjtu.edu.cn</a>，具体详情如下：
        </p>


        <details class="chinese">
            <summary><strong style="font-family: sans-serif">点击查看申请要求</strong></summary>
            <p class="bg_blue">
                <strong style="color: blue; font-family: sans-serif">本科实习生申请：</strong>
            <ul>
                <li>基本要求：上海交通大学本科大一，大二，大三学生</li>
                <li>附件材料：简历</li>
                <li>邮件题目：本科实习-姓名-专业</li>
            </ul>
            更多关于本科实习的信息请见<a href="/recruit/2024.html" class="first">详情</a>。
            </p>
            <p class="bg_blue">
                <strong style="color: blue; font-family: sans-serif">硕士、博士申请</strong>
            <ul>
                <li>基本要求：直博需获得当年所在学校的推免名额，普博需入学时获得硕士学位</li>
                <li>附件材料：简历</li>
                <li>邮件题目：硕士申请-姓名-学校，直博申请-姓名-学校，普博申请-姓名-在读学校</li>
            </ul>
            </p>

            <p class="bg_red">
                <strong style="color: red; font-family: sans-serif">博士后申请</strong>
            <ul>
                <li>基本要求：入职时获得博士学位</li>
                <li>附件材料：简历</li>
                <li>邮件题目：博士后申请-姓名-博士毕业学校</li>
            </ul>
            </p>

            <p class="bg_red">
                <strong style="color: red; font-family: sans-serif">Research AP（研究助理教授/研究员）申请</strong>
            <ul>
                <li>基本要求：获得博士学位，第一作者（含共一）身份发表5篇及以上AI和机器人领域高质量论文</li>
                <li>政策与待遇：中级职称，通过申请可获得硕士生导师资格；第一个聘请为三年，通过考核可在上海交通大学晋升为副教授，工资待遇优厚</li>
                <li>附件材料：简历</li>
                <li>邮件题目：研究助理教授-姓名-博士毕业学校</li>
            </ul>
            </p>
        </details>




    </div>

    <div class="container">
        <h2>Short Bio</h2>
        <p>
            <b>Cewu Lu</b>, Professor at Shanghai Jiao Tong University, Distinguished Professor of the Changjiang
            Scholars Program (长江学者特聘教授), and recipient of the Scientific Exploration Award. In 2016, he was selected as
            a high-level overseas young talent, and in 2018, he was named one of the 35 Innovators Under 35 in China by
            MIT Technology Review (MIT TR35). In 2019, he received the Qiushi Outstanding Young Scholar Award,
            and in
            2020, he was the third contributor to the Shanghai Science and Technology Progress Special Award. In 2022,
            he received the Ministry of Education Youth Science Award and was recognized for one of the six best papers
            at IROS (out of 3579 submissions). In 2023, he was nominated for the Best
            System Paper Award at the Robotics: Science and Systems (RSS) conference (one of four nominations) and
            received the Scientific Exploration Award (the only recipient in the field of embodied intelligence).
            <br><br>
            Before he joined SJTU, he was a research fellow at Stanford University working under Prof. Fei-Fei Li and
            Prof. Leonidas J. Guibas. He was a Research Assistant Professor at Hong Kong University of Science and
            Technology with Prof. Chi Keung Tang. He got the his PhD degree from The Chinese Univeristy of Hong Kong,
            supervised by Prof. Jiaya Jia.
            <br><br>
            As a corresponding author or first author, he has published more than 100 papers in high-impact journals and
            conferences, including <b>Nature</b>, <b>Nature Machine Intelligence</b>, and TPAMI. He serves as a reviewer
            for Science,
            Nature sub-journals, Cell sub-journals, and as area chair for NeurIPS, CVPR, ICCV, ECCV, IROS, and ICRA. His
            research interests include embodied intelligence and computer vision.
        </p>

        <hr width="80%">

        <p class="chinese">
            卢策吾老师曾在斯坦福大学人工智能实验室（导师：李飞飞，Leo Guibas）从事博士后研究。近年来获长江学者特聘教授，国家青年千人计划，《麻省理工科技评论》35位35岁以下科技精英（MIT
            TR35），科学探索奖（全国具身智能方向唯一），求是杰出青年学者，教育部青年科学奖，科学中国人杰出青年科学家，多年获得爱思唯尔Elsevier中国高被引学者等奖项荣誉。国际机器人顶会IROS、ICRA最佳论文获得者。担任《Nature》《Science》审稿人，CVPR、ICCV、ECCV、NeurIPS、AAAI等人工智能顶会的领域主席。
            累计以第一或通讯作者发表CCF-A类期刊、会议论文100余篇，总引用量超过2万，包括《Nature》正刊，《Nature》机器智能子刊（上海交大第一篇），TPAMI，IJCV，T-RO，IJRR（机器人领域TOP期刊）等。
        </p>

    </div>

    <div class="container">
        <h2>Our Task and Vision</h2>
        <p>
            The development of <b>Robots for general-purpose</b> has long been a shared dream of humanity, as their
            realization
            would significantly enhance productivity—by, for instance, performing tasks typically undertaken by nurses
            or cleaning staff—and improve the quality of life through applications such as domestic service robots. A
            general-purpose robot must be capable of executing a wide range of tasks in diverse and open-ended
            environments, posing a formidable challenge in the field of artificial intelligence. The crux of this
            challenge lies in enabling robots to acquire human behavioral capabilities.

            Building upon a strong foundation in the visual understanding of human behavior, we aim to explore a novel
            approach: empowering robots to learn comprehensive, general-purpose behaviors by observing and interpreting
            vast amounts of human activity in video form. Compared to the mainstream
            approach of guiding robotic behavior through large language models, our strategy offers several advantages
            in achieving generalizability:
        <ul>
            <li><b>Autonomous Learning:</b> Human behavior videos capture the full scope of tasks and their various
                possibilities, circumventing the limitations of manually defined tasks.</li><br>
            <li><b>Scalability:</b> The extensive accumulation of videos through the growth of the internet covers
                nearly
                every conceivable human task and operation.</li><br>
            <li><b>Automatic Expansion:</b> With large volumes of new videos uploaded daily, robots can automatically
                extend
                their capabilities to include new tasks and skills.</li>
        </ul>

        By implementing this innovative approach, we pave the way for a more universally applicable and effective
        solution to the challenge of creating general-purpose robots.
        </p>

        <!-- <hr width="80%"> -->
        <br>
        <div class="image_line">
            <img src="recruit/2024/机器人刮胡子.gif" width="180px">
            <img src="recruit/2024/机器人叠衣服.gif" width="180px">
            <img src="recruit/2024/机器人削黄瓜.gif" width="180px">
            <img src="recruit/2024/机器人收拾家务.gif" width="180px">
        </div>
        <br>

        <!-- <hr width="80%"> -->

        <p class="chinese">
            实验室研究方向为通用机器人（具身智能），是实现通用人工智能的重要分支。与被动接收信息不同，具身智能强调智能体主动与物理环境进行交互。人类也在文艺作品里描绘过很多浪漫的机器人故事，比如《机器管家》中的安德鲁、《机器人总动员》中的瓦利和夏娃、《星球大战》里的R2-D2和C-3PO等等。
            具身智能驱动的通用机器人将是人工智能的终极状态，也是目前国际学术和产业前沿。英伟达CEO黄仁勋在2023 world ITF大会表示：The next wave of AI, known as embodied
            AI, refers to intelligent systems that can understand, reason about, and interact with the physical
            world。即，人工智能的下一波浪潮被称为具身智能，它指的是能够理解、推理和与物理世界互动的智能系统。期待大家的加入和我们一起推动推动具身智能的变革。
        </p>

    </div>

    <!-- <div class="container">
        <h2>News</h2>
        <p>
            [2024] Six papers were accepted by ECCV 2024.
            <br>
            <br>
            [2024] Four papers were accepted by ICRA 2024.
            <br>
            <br>
            [2024] Five papers were accepted by CVPR 2024.
            <br>
            <br>
            [2022] One paper was accepted by <strong>Nature</strong> (One of two corresponding authors)
            <a href="https://www.nature.com/articles/s41586-022-04507-5">Link</a>.
            <br>
            <br>
            [2022] Ten papers were accepted by CVPR 2022.
            <br>
            <br>
            [2020] One paper was accepted by <strong>Nature Machine Intelligence</strong>
            <a href="https://www.nature.com/articles/s42256-020-0168-3">Link</a>.
            <br>
            <br>
            [2020] The concept of the General-Purpose Intelligent Agent
            (<a href="https://www.sciencedirect.com/science/article/pii/S2095809919309075">GIA</a>)
            has been published in <strong>Engineering</strong>.
            <br>
            <br>
            [2020] Seven papers were accepted by <strong>CVPR</strong> 2020
            <a href="/publications.html">Link</a>.
            <br>
            <br>
            [2020] Prof. Lu Cewu will serve as an <strong>Area Chair</strong> for CVPR 2020.
            <br>
            <br>
            [2020] <b><a href="http://hake-mvig.cn">
                    <span style="color: red" size="6px">H</span><span style="color: blue" size="6px">A</span><span
                        style="color: red" size="6px">KE</span></a></b>: Human Activity Knowledge Engine begins trial
            operation!
            <a href="http://hake-mvig.cn">Link</a>.
            <br>
            <br>
            [2019] VALSE 2019: Knowledge Driven Human Activity Understanding
            <a href="/research/VALSE2019.html">Talk</a>.
            <br>
            <br>
            [2018] PRCV 2018: Activity Understanding meets 3D Representation
            <a href="/research/PRCV2019.html">Talk</a>.
            <br>
            <br>
            [2017] AlphaPose is released, a pose estimation system based on our RMPE[ICCV'17], relatively outperforms
            Mask RCNN by 8.2% on COCO dataset pose task.
            <a href="/research/alphapose.html">AlphaPose</a>.
            <br>
            <br>
            <!-- [Year] We propose a new task of Action Adverb recognition.
            <a href="/research/adha/adha.html">ADHA</a>.
            <br> -->
    <!-- [2017] Prof. Lu Cewu is selected as MIT TR35 - "MIT Technology Review, 35 Innovators Under 35 (China)"
            <a href="http://www.mittrchina.com/news/1623">MIT Technology Review</a>. -->
    </p>
    </div> -->

</body>

</html>